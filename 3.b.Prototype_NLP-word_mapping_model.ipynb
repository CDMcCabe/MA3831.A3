{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Length: 754861\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"stories.csv\", encoding='utf-8')\n",
    "story_list = df.stories.to_list()\n",
    "texts = ''.join(story_list[0:25])  # Using 25 stories for testing\n",
    "text = [[char.lower() for char in text if char in string.printable] for text in texts]\n",
    "# text = [[char for char in text if char not in string.punctuation] for text in texts]\n",
    "text = ''.join([j for i in text for j in i])\n",
    "print(f'Corpus Length: {len(text)}')\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words: 15511\n"
     ]
    }
   ],
   "source": [
    "# Creating character / word mappings\n",
    "\n",
    "# Word mappings\n",
    "words = sorted(list(set(text.split())))\n",
    "print(f'Unique words: {len(words)}')\n",
    "\n",
    "n_to_word = {n:word for n, word in enumerate(words)}\n",
    "word_to_n = {word:n for n, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset to test/train\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "length = len(text.split())\n",
    "\n",
    "# Length of extracted word mapping sequences\n",
    "seq_length = 100\n",
    "\n",
    "# Sets are 100 words, followed by the target word\n",
    "for i in range(0, length-seq_length, 1):\n",
    "    sequence = text.split()[i:i + seq_length]\n",
    "    label = text.split()[i + seq_length]\n",
    "    X.append([word_to_n[word] for word in sequence])\n",
    "    Y.append(word_to_n[label])\n",
    "n_patterns = len(X)\n",
    "print(f'Total patterns: {n_patterns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to appropriate shape LSTM (samples, time steps, features)\n",
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified/float(len(words))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100, 100)          80400     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15511)             1566611   \n",
      "=================================================================\n",
      "Total params: 1,768,211\n",
      "Trainable params: 1,768,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define LSTM Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2841/2841 [==============================] - 467s 160ms/step - loss: 7.3393 - accuracy: 0.0483\n",
      "Epoch 2/100\n",
      "2841/2841 [==============================] - 457s 161ms/step - loss: 7.0080 - accuracy: 0.0495\n",
      "Epoch 3/100\n",
      "2841/2841 [==============================] - 463s 163ms/step - loss: 6.9859 - accuracy: 0.0499\n",
      "Epoch 4/100\n",
      "2841/2841 [==============================] - 457s 161ms/step - loss: 6.9812 - accuracy: 0.0507\n",
      "Epoch 5/100\n",
      "2841/2841 [==============================] - 461s 162ms/step - loss: 6.9786 - accuracy: 0.0499\n",
      "Epoch 6/100\n",
      "2841/2841 [==============================] - 457s 161ms/step - loss: 6.9790 - accuracy: 0.0484\n",
      "Epoch 7/100\n",
      "2841/2841 [==============================] - 461s 162ms/step - loss: 6.9588 - accuracy: 0.0493\n",
      "Epoch 8/100\n",
      "2841/2841 [==============================] - 457s 161ms/step - loss: 6.9124 - accuracy: 0.0500\n",
      "Epoch 9/100\n",
      "2841/2841 [==============================] - 457s 161ms/step - loss: 6.8809 - accuracy: 0.0483\n",
      "Epoch 10/100\n",
      "2841/2841 [==============================] - 470s 165ms/step - loss: 6.8430 - accuracy: 0.0496\n",
      "Epoch 11/100\n",
      "2841/2841 [==============================] - 480s 169ms/step - loss: 6.8048 - accuracy: 0.0486\n",
      "Epoch 12/100\n",
      "2841/2841 [==============================] - 483s 170ms/step - loss: 6.7757 - accuracy: 0.0490\n",
      "Epoch 13/100\n",
      "2841/2841 [==============================] - 543s 191ms/step - loss: 6.7444 - accuracy: 0.0500\n",
      "Epoch 14/100\n",
      "2841/2841 [==============================] - 569s 200ms/step - loss: 6.7011 - accuracy: 0.0492\n",
      "Epoch 15/100\n",
      "2841/2841 [==============================] - 571s 201ms/step - loss: 6.6823 - accuracy: 0.0506\n",
      "Epoch 16/100\n",
      "2841/2841 [==============================] - 568s 200ms/step - loss: 6.6461 - accuracy: 0.0512\n",
      "Epoch 17/100\n",
      "2841/2841 [==============================] - 574s 202ms/step - loss: 6.6194 - accuracy: 0.0502\n",
      "Epoch 18/100\n",
      "2841/2841 [==============================] - 566s 199ms/step - loss: 6.5809 - accuracy: 0.0507\n",
      "Epoch 19/100\n",
      "2841/2841 [==============================] - 559s 197ms/step - loss: 6.5565 - accuracy: 0.0514\n",
      "Epoch 20/100\n",
      "2841/2841 [==============================] - 576s 203ms/step - loss: 6.5236 - accuracy: 0.0525\n",
      "Epoch 21/100\n",
      "2841/2841 [==============================] - 570s 201ms/step - loss: 6.4824 - accuracy: 0.0520\n",
      "Epoch 22/100\n",
      "2841/2841 [==============================] - 568s 200ms/step - loss: 6.4375 - accuracy: 0.0525\n",
      "Epoch 23/100\n",
      "2841/2841 [==============================] - 570s 200ms/step - loss: 6.4159 - accuracy: 0.0511\n",
      "Epoch 24/100\n",
      "2841/2841 [==============================] - 566s 199ms/step - loss: 6.3705 - accuracy: 0.0526\n",
      "Epoch 25/100\n",
      "2841/2841 [==============================] - 571s 201ms/step - loss: 6.3484 - accuracy: 0.0520\n",
      "Epoch 26/100\n",
      "2841/2841 [==============================] - 573s 202ms/step - loss: 6.3164 - accuracy: 0.0526\n",
      "Epoch 27/100\n",
      "2841/2841 [==============================] - 574s 202ms/step - loss: 6.2630 - accuracy: 0.0520\n",
      "Epoch 28/100\n",
      "2841/2841 [==============================] - 573s 202ms/step - loss: 6.2326 - accuracy: 0.0526\n",
      "Epoch 29/100\n",
      "2841/2841 [==============================] - 578s 203ms/step - loss: 6.1891 - accuracy: 0.0532\n",
      "Epoch 30/100\n",
      "2841/2841 [==============================] - 577s 203ms/step - loss: 6.1587 - accuracy: 0.0522\n",
      "Epoch 31/100\n",
      "2841/2841 [==============================] - 579s 204ms/step - loss: 6.1297 - accuracy: 0.0541\n",
      "Epoch 32/100\n",
      "2841/2841 [==============================] - 577s 203ms/step - loss: 6.0952 - accuracy: 0.0539\n",
      "Epoch 33/100\n",
      "2841/2841 [==============================] - 576s 203ms/step - loss: 6.0798 - accuracy: 0.0540\n",
      "Epoch 34/100\n",
      "2841/2841 [==============================] - 577s 203ms/step - loss: 6.0277 - accuracy: 0.0539\n",
      "Epoch 35/100\n",
      "2841/2841 [==============================] - 576s 203ms/step - loss: 6.0061 - accuracy: 0.0544\n",
      "Epoch 36/100\n",
      "2841/2841 [==============================] - 577s 203ms/step - loss: 5.9666 - accuracy: 0.0559\n",
      "Epoch 37/100\n",
      "2841/2841 [==============================] - 585s 206ms/step - loss: 5.9440 - accuracy: 0.0544\n",
      "Epoch 38/100\n",
      "2841/2841 [==============================] - 582s 205ms/step - loss: 5.9205 - accuracy: 0.0555\n",
      "Epoch 39/100\n",
      "2841/2841 [==============================] - 584s 205ms/step - loss: 5.8876 - accuracy: 0.0564\n",
      "Epoch 40/100\n",
      "2841/2841 [==============================] - 584s 205ms/step - loss: 5.8729 - accuracy: 0.0582\n",
      "Epoch 41/100\n",
      "2841/2841 [==============================] - 584s 206ms/step - loss: 5.8390 - accuracy: 0.0575\n",
      "Epoch 42/100\n",
      "2841/2841 [==============================] - 585s 206ms/step - loss: 5.8084 - accuracy: 0.0593\n",
      "Epoch 43/100\n",
      "2841/2841 [==============================] - 585s 206ms/step - loss: 5.7845 - accuracy: 0.0604\n",
      "Epoch 44/100\n",
      "2841/2841 [==============================] - 586s 206ms/step - loss: 5.7669 - accuracy: 0.0600\n",
      "Epoch 45/100\n",
      "2841/2841 [==============================] - 584s 206ms/step - loss: 5.7413 - accuracy: 0.0600\n",
      "Epoch 46/100\n",
      "2841/2841 [==============================] - 583s 205ms/step - loss: 5.7132 - accuracy: 0.0624\n",
      "Epoch 47/100\n",
      "2841/2841 [==============================] - 584s 205ms/step - loss: 5.7007 - accuracy: 0.0626\n",
      "Epoch 48/100\n",
      "2841/2841 [==============================] - 586s 206ms/step - loss: 5.6803 - accuracy: 0.0631\n",
      "Epoch 49/100\n",
      "2841/2841 [==============================] - 586s 206ms/step - loss: 5.6601 - accuracy: 0.0660\n",
      "Epoch 50/100\n",
      "2841/2841 [==============================] - 584s 206ms/step - loss: 5.6432 - accuracy: 0.0663\n",
      "Epoch 51/100\n",
      "2841/2841 [==============================] - 588s 207ms/step - loss: 5.6289 - accuracy: 0.0655\n",
      "Epoch 52/100\n",
      "2841/2841 [==============================] - 587s 207ms/step - loss: 5.6082 - accuracy: 0.0656\n",
      "Epoch 53/100\n",
      "2841/2841 [==============================] - 584s 206ms/step - loss: 5.5890 - accuracy: 0.0677\n",
      "Epoch 54/100\n",
      "2841/2841 [==============================] - 589s 207ms/step - loss: 5.5713 - accuracy: 0.0683\n",
      "Epoch 55/100\n",
      "2841/2841 [==============================] - 587s 206ms/step - loss: 5.5561 - accuracy: 0.0688\n",
      "Epoch 56/100\n",
      "2841/2841 [==============================] - 583s 205ms/step - loss: 5.5441 - accuracy: 0.0702\n",
      "Epoch 57/100\n",
      "2841/2841 [==============================] - 584s 206ms/step - loss: 5.5206 - accuracy: 0.0715\n",
      "Epoch 58/100\n",
      "2841/2841 [==============================] - 583s 205ms/step - loss: 5.5139 - accuracy: 0.0731\n",
      "Epoch 59/100\n",
      "2841/2841 [==============================] - 599s 211ms/step - loss: 5.4926 - accuracy: 0.0740\n",
      "Epoch 60/100\n",
      "2841/2841 [==============================] - 577s 203ms/step - loss: 5.4852 - accuracy: 0.0741\n",
      "Epoch 61/100\n",
      "2841/2841 [==============================] - 601s 212ms/step - loss: 5.4708 - accuracy: 0.0761\n",
      "Epoch 62/100\n",
      "2841/2841 [==============================] - 608s 214ms/step - loss: 5.4540 - accuracy: 0.0760\n",
      "Epoch 63/100\n",
      "2841/2841 [==============================] - 598s 211ms/step - loss: 5.4440 - accuracy: 0.0764\n",
      "Epoch 64/100\n",
      "2841/2841 [==============================] - 607s 214ms/step - loss: 5.4281 - accuracy: 0.0783\n",
      "Epoch 65/100\n",
      "2841/2841 [==============================] - 598s 210ms/step - loss: 5.4091 - accuracy: 0.0802\n",
      "Epoch 66/100\n",
      "2841/2841 [==============================] - 583s 205ms/step - loss: 5.4122 - accuracy: 0.0781\n",
      "Epoch 67/100\n",
      "2841/2841 [==============================] - 582s 205ms/step - loss: 5.3943 - accuracy: 0.0782\n",
      "Epoch 68/100\n",
      "2841/2841 [==============================] - 585s 206ms/step - loss: 5.3808 - accuracy: 0.0815\n",
      "Epoch 69/100\n",
      "2841/2841 [==============================] - 588s 207ms/step - loss: 5.3799 - accuracy: 0.0826\n",
      "Epoch 70/100\n",
      "2841/2841 [==============================] - 585s 206ms/step - loss: 5.3725 - accuracy: 0.0828\n",
      "Epoch 71/100\n",
      "2841/2841 [==============================] - 586s 206ms/step - loss: 5.3647 - accuracy: 0.0842\n",
      "Epoch 72/100\n",
      "2841/2841 [==============================] - 585s 206ms/step - loss: 5.3520 - accuracy: 0.0850\n",
      "Epoch 73/100\n",
      "2841/2841 [==============================] - 585s 206ms/step - loss: 5.3424 - accuracy: 0.0851\n",
      "Epoch 74/100\n",
      "2841/2841 [==============================] - 586s 206ms/step - loss: 5.3313 - accuracy: 0.0871\n",
      "Epoch 75/100\n",
      "2841/2841 [==============================] - 586s 206ms/step - loss: 5.3220 - accuracy: 0.0867\n",
      "Epoch 76/100\n",
      "2841/2841 [==============================] - 586s 206ms/step - loss: 5.3035 - accuracy: 0.0879\n",
      "Epoch 77/100\n",
      "2841/2841 [==============================] - 587s 207ms/step - loss: 5.3153 - accuracy: 0.0885\n",
      "Epoch 78/100\n",
      "2841/2841 [==============================] - 587s 207ms/step - loss: 5.2910 - accuracy: 0.0910\n",
      "Epoch 79/100\n",
      "2841/2841 [==============================] - 588s 207ms/step - loss: 5.2907 - accuracy: 0.0903\n",
      "Epoch 80/100\n",
      "2841/2841 [==============================] - 602s 212ms/step - loss: 5.2868 - accuracy: 0.0894\n",
      "Epoch 81/100\n",
      "2841/2841 [==============================] - 599s 211ms/step - loss: 5.2733 - accuracy: 0.0912\n",
      "Epoch 82/100\n",
      "2841/2841 [==============================] - 596s 210ms/step - loss: 5.2668 - accuracy: 0.0927\n",
      "Epoch 83/100\n",
      "2841/2841 [==============================] - 605s 213ms/step - loss: 5.2631 - accuracy: 0.0923\n",
      "Epoch 84/100\n",
      "2841/2841 [==============================] - 602s 212ms/step - loss: 5.2596 - accuracy: 0.0932\n",
      "Epoch 85/100\n",
      "2841/2841 [==============================] - 602s 212ms/step - loss: 5.2467 - accuracy: 0.0939\n",
      "Epoch 86/100\n",
      "2841/2841 [==============================] - 604s 213ms/step - loss: 5.2410 - accuracy: 0.0935\n",
      "Epoch 87/100\n",
      "2841/2841 [==============================] - 588s 207ms/step - loss: 5.2335 - accuracy: 0.0965\n",
      "Epoch 88/100\n",
      "2841/2841 [==============================] - 591s 208ms/step - loss: 5.2284 - accuracy: 0.0951\n",
      "Epoch 89/100\n",
      "2841/2841 [==============================] - 605s 213ms/step - loss: 5.2200 - accuracy: 0.0967\n",
      "Epoch 90/100\n",
      "2841/2841 [==============================] - 611s 215ms/step - loss: 5.2160 - accuracy: 0.0983\n",
      "Epoch 91/100\n",
      "2841/2841 [==============================] - 607s 214ms/step - loss: 5.2181 - accuracy: 0.0970\n",
      "Epoch 92/100\n",
      "2841/2841 [==============================] - 599s 211ms/step - loss: 5.8362 - accuracy: 0.0817\n",
      "Epoch 93/100\n",
      "2841/2841 [==============================] - 597s 210ms/step - loss: 6.8300 - accuracy: 0.0541\n",
      "Epoch 94/100\n",
      "2841/2841 [==============================] - 603s 212ms/step - loss: 6.6593 - accuracy: 0.0573\n",
      "Epoch 95/100\n",
      "2841/2841 [==============================] - 603s 212ms/step - loss: 6.6866 - accuracy: 0.0567\n",
      "Epoch 96/100\n",
      "2841/2841 [==============================] - 593s 209ms/step - loss: 6.5849 - accuracy: 0.0598\n",
      "Epoch 97/100\n",
      "2841/2841 [==============================] - 600s 211ms/step - loss: 6.4542 - accuracy: 0.0621\n",
      "Epoch 98/100\n",
      "2841/2841 [==============================] - 608s 214ms/step - loss: 6.3990 - accuracy: 0.0651\n",
      "Epoch 99/100\n",
      "2841/2841 [==============================] - 609s 214ms/step - loss: 6.4730 - accuracy: 0.0586\n",
      "Epoch 100/100\n",
      "2841/2841 [==============================] - 600s 211ms/step - loss: 6.3817 - accuracy: 0.0635\n"
     ]
    }
   ],
   "source": [
    "# Fit Model\n",
    "model.fit(X_modified, Y_modified, epochs=100, batch_size=50)\n",
    "\n",
    "filename = '100_0.2_100_0.2_100_0.2_e100_b50.h5'\n",
    "model.save_weights(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " boilover. maybe the attacker truly believed his life was in danger and mistook the slightest movement as the beginning of a punch. perhaps he just let his anger at the situation get the best of him. maybe a mix of both. whats the objective truth here? and for whom is that truth valid? when youre a cop, understanding these nuances in truth is critical. and, understanding the power those nuances can have is even more important. not only when we have to discern whether or not someones recollection of events is accurate, but when we lie to achieve a specific loss. the the i the i the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the i the\n"
     ]
    }
   ],
   "source": [
    "# Generate texts with last saved fit\n",
    "model.load_weights(filename)\n",
    "\n",
    "string_mapped = X[99]\n",
    "full_string = [n_to_word[value] for value in string_mapped]\n",
    "\n",
    "# Generation\n",
    "for i in range(100):\n",
    "    x = np.reshape(string_mapped, (1, len(string_mapped), 1))\n",
    "    x = x / float(len(words))\n",
    "    \n",
    "    pred_index = np.argmax(model.predict(x, verbose = 0))\n",
    "    seq = [n_to_word[value] for value in string_mapped]\n",
    "    full_string.append(n_to_word[pred_index])\n",
    "    \n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]\n",
    "    \n",
    "# Combine generated text and output\n",
    "txt = \"\"\n",
    "for word in full_string:\n",
    "    txt = txt+' '+word\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
